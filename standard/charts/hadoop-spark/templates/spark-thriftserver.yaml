{{if .Values.thriftserver.enable}}
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: {{.Release.Name}}-spark-thriftserver
  labels:
    app:  {{.Release.Name}}-spark-thriftserver
spec:
  replicas: {{.Values.thriftserver.replicas}}
  serviceName: {{.Release.Name}}-spark-thriftserver-headless
  selector:
    matchLabels:
      app:  {{.Release.Name}}-spark-thriftserver
  template:
    metadata:
      labels:
        app:  {{.Release.Name}}-spark-thriftserver
    spec:
      nodeSelector:
      {{ toYaml .Values.thriftserver.nodeSelector | indent 8 }}
      containers:
        - name: spark-thriftserver
          image: {{.Values.image}}
          imagePullPolicy: Always
          livenessProbe:
            tcpSocket:
              port: 10000
            initialDelaySeconds: 30
            timeoutSeconds: 5
          # todo 增加Fair调度和executor num，服务监控检查
          command: [ "/bin/sh","-c","/opt/spark/sbin/start-thriftserver.sh    --master yarn;  tail -f /opt/spark/logs/spark--org.apache.spark.sql.hive.thriftserver.HiveThriftServer2-1-$MY_POD_NAME.out; " ]
          env:
            - name: TZ
              value: "Asia/Shanghai"
            - name: MY_POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: MY_POD_NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            - name: MY_POD_IP
              valueFrom:
                fieldRef:
                  fieldPath: status.podIP
            - name: HADOOP_CONF_DIR
              value: /opt/spark/conf
          volumeMounts:
            - name: spark-conf
              mountPath: /opt/spark/conf/spark-defaults.conf
              subPath: spark-defaults.conf
            - name: spark-conf
              mountPath: /opt/spark/conf/spark-env.sh
              subPath: spark-env.sh
            - name: hadoop-fs-conf
              mountPath: /opt/spark/conf/core-site.xml
              subPath: core-site.xml
            - name: hadoop-fs-conf
              mountPath: /opt/spark/conf/hdfs-site.xml
              subPath: hdfs-site.xml
            - name: hadoop-yarn-conf
              mountPath: /opt/spark/conf/yarn-site.xml
              subPath: yarn-site.xml
            - name: hadoop-hive-conf
              mountPath: /opt/spark/conf/hive-site.xml
              subPath: hive-site.xml
            - name: hadoop-yarn-conf
              mountPath: /opt/spark/conf/mapred-site.xml
              subPath: mapred-site.xml
      volumes:
        - name: spark-conf
          configMap:
            name: {{.Release.Name}}-spark-conf-map
        - name: hadoop-fs-conf
          configMap:
              name: {{template "spark.hadoop-fs-conf" .}}
        - name: hadoop-yarn-conf
          configMap:
            name: {{template "spark.hadoop-yarn-conf" .}}
        - name: hadoop-hive-conf
          configMap:
            name: {{template "spark.hadoop-hive-conf" .}}

---
apiVersion: v1
kind: Service
metadata:
  name: {{.Release.Name}}-spark-thriftserver-svc
spec:
  ports:
    - port: 10000
      protocol: TCP
      name: spark-thriftserver-port

  selector:
    # same of pod label
    app: {{.Release.Name}}-spark-thriftserver
---
kind: Service
apiVersion: v1

metadata:
  name: {{.Release.Name}}-spark-thriftserver-headless
  labels:
    app: {{.Release.Name}}-spark-thriftserver
spec:
  selector:
    app: {{.Release.Name}}-spark-thriftserver
  clusterIP: None
  type: ClusterIP
  publishNotReadyAddresses: true

{{end}}